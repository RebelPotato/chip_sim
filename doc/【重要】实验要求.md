# 类脑计算芯片SystemC仿真设计实践

## 实验目的

1. 以乘加器阵列的设计和使用为例，对比RTL级、行为级、时序级芯片仿真；
2. 在一套现有的仿真器框架中完成部分算子的编写，并使用仿真器运行一层或多层神经网络。

 

## 实验内容

### 1.  仿真层次对比

阅读并运行`tutorial`分支下的MAC_array_demo项目，与Verilog版本的代码进行比较。

### 2. 芯片架构设计

在C++开发环境下，在一套现有的行为级仿真器框架中完成部分算子的编写，并使用仿真器运行一层或多层神经网络。

现有仿真器中模拟的芯片整体架构请参考`第十二周 SystemC实验介绍`PPT；数据存储方式请参考`数据存储方式说明.pdf`；指令集请参考`指令集V1.xlsx`和`指令集说明.pdf`。

代码结构请参考`代码结构.md`，代码运行流程请参考`运行流程.pdf`

下面介绍实验具体内容和要求

#### 2.1  功能实现：添加基础指令（必做）

在现有仿真器中添加至少一条指令，然后调用仿真器实现至少一层神经网络功能（自行确定规模、参数），需要包括至少一个突触运算算子（如卷积、全连接）和一个激活运算算子（如ReLU、Sigmoid、LIF等）。需要自己**验证计算功能正确**（例如与Pytorch结果对比）。
* 推荐所有计算都使用浮点数类型

#### 2.2 功能实现：添加指令（选做）

在现有仿真器中添加多条指令，并对其功能进行验证。

#### 2.3 模拟器使用（选做）

在[2.1节](#2.1  功能实现：添加基础指令（必做）)的基础上，设计新指令（只需明确定义新指令的功能，可以不在仿真器中实现）。假如基本架构不变，使用指令集实现多层神经网络或一个小规模完整神经网络——需要明确使用的指令、顺序、数量、每条指令的参数。需要考虑从所有数据的具体存储和运算。
#### 2.4 功能实现：不同精度运算（选做）
在[2.1节](#2.1  功能实现：添加基础指令（必做）)的基础上，尝试加入不同数据类型，如整数运算（一般使用Int8乘，Int32累加）、脉冲输入计算等等。

### 3.  架构探索（选做）

#### 3.1 调整存储容量

在添加计算指令的基础上，可以对**存储**进行修改，观察其影响。

目前的对架构影响较大的存储有两块，一是片外的DRAM，二是片上的SRAM。

片外DRAM的大小可以在```core_controller.cpp```中修改：

```c++
dram<sc_bv<PORT_WIDTH> > offchip_dram("offchip_dram", 0, 10000,sync_event, trace_event_queue_tb);
```

如果把DRAM看作一个数组，那么 ```sc_bv<PORT_WIDTH>``` 就是数组中的数据类型（DRAM的位宽），`0` 代表数组的起始编号（DRAM的起始地址），`10000` 代表数组的结束编号（DRAM的结束地址）。DRAM的存储空间大小可以简单表示为
$$
DRAM\ capacity=width \times (end\ address-start\ address)
$$
片上SRAM的大小也在```core_controller.cpp```中修改：

```c++
Cmem_controller<sc_bv<PORT_WIDTH> > mem_ctrl("mem_crtl", 0, 1000,sync_event,trace_event_queue_tb);
```

`Cmem_controller` 内部有一块SRAM，通过在`Cmem_controller` 的构造函数中指定位宽、起始地址和结束地址，可以调整SRAM的大小。

现有框架的实现较为简单，将存储的位宽与指令长度直接绑定（`PORT_WIDTH` 定义在 `config.h` 文件中）。所以建议调整存储容量时只调整深度。

#### 3.2 查看性能情况

在 `core_controller.cpp` 的最后，程序会自动输出存储造成的开销。

```c++
std::cout << "DRAM random access times: " << dram<sc_bv<PORT_WIDTH> >::random_access_times << std::endl;
std::cout << "DRAM burst access times: " << dram<sc_bv<PORT_WIDTH> >::burst_access_times << std::endl;
std::cout << "DRAM area: " << dram<sc_bv<PORT_WIDTH> >::area << std::endl;
std::cout << "DRAM refresh energy: " << dram<sc_bv<PORT_WIDTH> >::area * tb.simulater_time * RAM_REFRESH_POWER<< std::endl;
std::cout << "DRAM total access latency: " << dram<sc_bv<PORT_WIDTH> >::total_access_latency << std::endl;
std::cout << "DRAM energy consumption: " << dram<sc_bv<PORT_WIDTH> >::energy_consumption << std::endl;

std::cout << "SRAM random access times: " << ram<sc_bv<PORT_WIDTH> >::random_access_times << std::endl;
std::cout << "SRAM area: " << ram<sc_bv<PORT_WIDTH> >::area << std::endl;
std::cout << "SRAM static energy: " << ram<sc_bv<PORT_WIDTH> >::area * tb.simulater_time * RAM_STATIC_POWER << std::endl;
std::cout << "SRAM total access latency: " << ram<sc_bv<PORT_WIDTH> >::total_access_latency << std::endl;
std::cout << "SRAM energy consumption: " << ram<sc_bv<PORT_WIDTH> >::energy_consumption << std::endl;
```

一般来说，面积（area）越小越好，代表芯片制造成本低；延迟（latency）越小越好，代表完成任务的速度快；能耗（energy consumption）越小越好，代表完成任务消耗的能量少。

#### 3.3 探索方法

存储对架构首先在功能上，所有计算都需要存储，如果存储存储容量或带宽较小，完成一个较大规模的计算可能不能一次完成；当完成任务的过程发生变化后，[3.2节](#3.2 查看性能情况)中提到的各种指标也会变化，因此存储对性能也有很大的影响。

探索存储大小的参考过程如下：

1. 确定一个或多个任务：例如完成一个卷积层运算
2. 确定任务的规模：例如确定卷积的输入激活的通道数、长、宽，卷积核的数量（输出通道数）、长、宽等等参数
3. 调整存储容量
4. 设计完成任务的过程（参考 [2.3 模拟器使用（选做）](#2.3 模拟器使用（选做）)）
5. 运行模拟器，查看各个性能指标的变化
6. 重复3、4、5步骤

注意事项：

* 存储容量受到指令位宽约束，目前的SRAM地址分配了16位，DRAM地址分配了32位
* 如果任务规模较小而存储容量较大，那么存储的调整可能不会造成影响，因此在探索时可以从一些极端情况开始尝试，例如SRAM的深度非常小或DRAM的深度非常小的情况
* 可以尝试去掉SRAM和DRAM，但需要改动架构
  * 去掉SRAM会造成 `Cmem_controller` 的行为发生较大变化，并且没有Load、Store两条指令
  * 去掉DRAM会造成芯片启动过程和 `Cmem_controller` 的行为发生较大变化，可以假设外部CPU能直接访问片上SRAM，同样没有Load、Store两条指令
* 单一的面积、速度或功耗都不是衡量架构好坏的标准（为什么？），可以采用他们之间的某些比值作为评估标准

## 实验要求

* 2人一组（允许有一组1人或3人），共同开发
* 在第16周课上对上述实验成果进行展示。每组展示不超过12分钟，提问3~10分钟。展示内容包括：
  * 小组分工
  * 数字电路设计的体会，对RTL级、行为级、时序级芯片仿真的体会（如果有）
  * 必做实验过程与结果，可以包括：
    * 添加的指令介绍
    * 添加的指令在仿真器中实现方法介绍，详细介绍计算流程（读数据、计算和写数据的顺序、次数等）
    * 神经网络选取、指令参数
    * 最后验证的结果
    * 思考：自己在行为级仿真器中写的计算流程如果变成电路大概是什么样的？在电路上是否容易实现？为什么？
    * ……
  * 选做内容或自己探索的内容（如果有），也可将选做内容作为思考题谈谈看法
  * 思考、建议……
* 提交展示PPT和展示中涉及的所有代码（仅存档）
